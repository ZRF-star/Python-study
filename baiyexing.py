import array
import re
from tkinter import _flatten

import matplotlib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from sklearn import metrics

from sklearn.metrics import classification_report
from sklearn.naive_bayes import MultinomialNB  #å¯¼å…¥æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
from sklearn.model_selection import train_test_split #å¯¼å…¥è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ¨¡å—train_test_split
import jieba
import wordcloud
from wordcloud import ImageColorGenerator, STOPWORDS

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('expand_frame_repr', False)#ç¦æ­¢è‡ªåŠ¨æ¢è¡Œ

f = pd.read_excel("ç™½å¤œè¡Œ1.xlsx")

# æå–æ˜Ÿçº§
f['star'] = f.rating_num.str.extract(r'(\d)')

# åˆ é™¤åˆ—
f = f.drop(['rating_num', 'user_url', 'comment_time'], axis=1)
# å¼‚å¸¸å€¼
#f['content'] = f.content.replace('ğŸ¤¨', 'å¾®ç¬‘')
print(f)

#æ•°æ®é¢„å¤„ç†
#ä¸­æ–‡åˆ†è¯
contents = f['content']
contents = list(contents)
contents1 = list()
for content in contents:#å»é™¤æ ‡ç‚¹ç¬¦å·
    comp = re.compile('[^A-Z^a-z^0-9^\u4e00-\u9fa5]')
    content = comp.sub('', content)
    contents1.append(content)
print("ä¸­æ–‡åˆ†è¯ï¼š")
print(contents1)

#åˆ†è¯
stopwords = open("stopwords.txt", encoding="utf-8")
stopwords1 = list()
for stopword in stopwords.readlines():
    curLine = stopword.strip().split(" ")
    stopwords1.append(curLine)
stopwords1 = list(_flatten(stopwords1))#äºŒç»´è½¬ä¸€ç»´
print("åœç”¨è¯ï¼š")
print(stopwords1)

new_Series = pd.Series()
#å¤„ç†åœç”¨è¯
new_list = list()
for content1 in contents1:
    ls = list(jieba.cut_for_search(content1))
    ls = [w for w in ls if w not in stopwords1]
    txt = " ".join(ls)
    new_list.append(txt)
print("å»é™¤åœç”¨è¯ï¼š")
print(new_list)
new_Series = pd.Series(new_list)
f['content'] = new_Series

star = list(f['star'])
star1 = list()
for s in star:
    if s == s:
        star1.append(int(s))
    else:
        star1.append(0)

print("=============================å¯è§†åŒ–=======================")
# è®¡æ•°
star_num = f.star.value_counts()
star_num = star_num.sort_index()
print(star_num)
print("====================è¯äº‘å›¾=====================")
print("===========ç»˜åˆ¶é¥¼å›¾================")
matplotlib.rcParams['font.family'] = 'Kaiti'#è®©ä¸­æ–‡å­—ä½“æ­£å¸¸æ˜¾ç¤º
labels = '1æ˜Ÿ', '2æ˜Ÿ', '3æ˜Ÿ', '4æ˜Ÿ', '5æ˜Ÿ'
sizes = list(star_num)
plt.pie(sizes, explode=None, labels=labels, autopct='%1.1f%%')
plt.title("è±†ç“£è¯„åˆ†æ¯”ä¾‹")
plt.axis('equal')
plt.show()
print("===================================ä¸‰ä¸ªè¯äº‘å›¾=========================")
text1 = f[(f.star=='4')|(f.star=='5')]['content']
positive = list(text1)
file = open("positive.txt", 'a')
for i in range(len(positive)):
    s = str(positive[i]).replace('[','').replace(']','')#å»é™¤[],è¿™ä¸¤è¡ŒæŒ‰æ•°æ®ä¸åŒï¼Œå¯ä»¥é€‰æ‹©
    s = s.replace("'",'').replace(',','') +'\n'   #å»é™¤å•å¼•å·ï¼Œé€—å·ï¼Œæ¯è¡Œæœ«å°¾è¿½åŠ æ¢è¡Œç¬¦
    file.write(s)
alice_coloring = np.array(Image.open('people-flower.jpg'))
f_w = open("positive.txt", "r")
t = f_w.read()
ls_w = jieba.lcut(t)
txt_w = " ".join(ls_w)
w = wordcloud.WordCloud(font_path="msyh.ttc", background_color="black",
                        mask=alice_coloring, collocations=False,
                        stopwords=['ä¸€ç‚¹', 'è¿™éƒ¨','ç‰‡å­','å°æ—¶','åŠå°æ—¶',
                                   'å¥½å¥½','ç”µè§†å‰§','äººç‰©','ä¹‹é—´','ç”µè§†']
                        )
w.generate(t)
image_color = ImageColorGenerator(alice_coloring)
plt.imshow(w, interpolation='bilinear')
plt.title("æ­£å‘è¯„åˆ†åŸå› ")
plt.axis('off')
plt.show()
w.to_file("positive.png")
print("==================è´Ÿå‘è¯„åˆ†åŸå› ===============")
text2 = f[(f.star=='1')|(f.star=='2')]['content']
negative = list(text2)
file = open("negative.txt", 'a')
for i in range(len(negative)):
    s = str(negative[i]).replace('[','').replace(']','')#å»é™¤[],è¿™ä¸¤è¡ŒæŒ‰æ•°æ®ä¸åŒï¼Œå¯ä»¥é€‰æ‹©
    s = s.replace("'",'').replace(',','') +'\n'   #å»é™¤å•å¼•å·ï¼Œé€—å·ï¼Œæ¯è¡Œæœ«å°¾è¿½åŠ æ¢è¡Œç¬¦
    file.write(s)
alice_coloring = np.array(Image.open('people-flower.jpg'))
f_w = open("negative.txt", "r")
t = f_w.read()
ls_w = jieba.lcut(t)
txt_w = " ".join(ls_w)
w = wordcloud.WordCloud(font_path="msyh.ttc", background_color="black",
                        mask=alice_coloring, collocations=False,
                        stopwords=['ä¸€ç‚¹', 'è¿™éƒ¨','ç‰‡å­','å°æ—¶','åŠå°æ—¶',
                                   'å¥½å¥½','ç”µè§†å‰§','äººç‰©','ä¹‹é—´','å°è¯´','çœ‹è¿‡','ç”µè§†']
                        )
w.generate(t)
image_color = ImageColorGenerator(alice_coloring)
plt.imshow(w, interpolation='bilinear')
plt.title("è´Ÿå‘è¯„åˆ†åŸå› ")
plt.axis('off')
plt.show()
w.to_file("negative.png")
print("=============================ä¸­è¯„åŸå› ======================")
text3 = f[(f.star=='3')]['content']
medium = list(text3)
file = open("medium.txt", 'a')
for i in range(len(medium)):
    s = str(medium[i]).replace('[','').replace(']','')#å»é™¤[],è¿™ä¸¤è¡ŒæŒ‰æ•°æ®ä¸åŒï¼Œå¯ä»¥é€‰æ‹©
    s = s.replace("'",'').replace(',','') +'\n'   #å»é™¤å•å¼•å·ï¼Œé€—å·ï¼Œæ¯è¡Œæœ«å°¾è¿½åŠ æ¢è¡Œç¬¦
    file.write(s)
alice_coloring = np.array(Image.open('people-flower.jpg'))
f_w = open("medium.txt", "r")
t = f_w.read()
ls_w = jieba.lcut(t)
txt_w = " ".join(ls_w)
w = wordcloud.WordCloud(font_path="msyh.ttc", background_color="black",
                        mask=alice_coloring, collocations=False,
                        stopwords=['ä¸€ç‚¹', 'è¿™éƒ¨','ç‰‡å­','å°æ—¶','åŠå°æ—¶',
                                   'å¥½å¥½','ç”µè§†å‰§','äººç‰©','ä¹‹é—´','å°è¯´','çœ‹è¿‡',
                                   'ç”µè§†','çœ‹è¿‡','æ•…äº‹']
                        )
w.generate(t)
image_color = ImageColorGenerator(alice_coloring)
plt.imshow(w, interpolation='bilinear')
plt.title("ä¸­è¯„è¯„åˆ†åŸå› ")
plt.axis('off')
plt.show()
w.to_file("medium.png")
print("==================================================================================")
star2 = list()
for st in star1:
    if st > 3:
        st = 1
        star2.append(st)
    else:
        st = 0
        star2.append(st)
f['star'] = star2
print(f['star'])
print(f)

print("=============================æœ´ç´ è´å¶æ–¯======================")
clf = MultinomialNB()
x = f['content']
x = list(x)
y = f['star']
y = list(y)
n = len(x)//8
x_train, y_train = x[n:], y[n:]
x_train = pd.Series(x_train)
y_train = pd.Series(y_train)
x_test, y_test = x[:n], y[:n]
x_test = pd.Series(x_test)
y_test = pd.Series(y_test)


from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB
count_vec = CountVectorizer(max_df=0.8, min_df=3)
tfidf_vec = TfidfVectorizer()

def MNB_Classifier():
    return Pipeline([
        ('count_vec', CountVectorizer()),
        ('mnb', MultinomialNB())
    ])
mnbc_clf = MNB_Classifier()
# è¿›è¡Œè®­ç»ƒ
print("Start training...")
mnbc_clf.fit(x_train, y_train)
print("training done!")
answer_b = mnbc_clf.predict(x_test)
print("0ï¼šå·®è¯„å’Œä¸­è¯„ï¼›1ï¼šå¥½è¯„")
print(answer_b)
print("Prediction done!")
#å‡†ç¡®ç‡æµ‹è¯•
accuracy=metrics.accuracy_score(y_test,answer_b)
print('å‡†ç¡®ç‡ï¼š'+str(accuracy))
print("The classification report for b:")
print(classification_report(y_test, answer_b))






